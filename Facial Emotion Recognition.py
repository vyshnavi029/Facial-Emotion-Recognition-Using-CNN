# -*- coding: utf-8 -*-
"""ML_2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dUqQ0V-788JSd3DiRrGbrFLXLitedlrX
"""

!pip install -q kaggle

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/

!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d muhammadhananasghar/human-emotions-datasethes

!unzip '/content/human-emotions-datasethes.zip' -d '/content/drive/MyDrive/dataset003 (1)'

"""**Importing libraries and Configuration**"""

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import r2_score

# Configuration settings
CONFIGURATION = {
    "BATCH_SIZE": 32,
    "IM_SIZE": 256,
    "LEARNING_RATE": 1e-3,
    "N_EPOCHS": 10,
    "DROPOUT_RATE": 0.5,  # Added dropout rate
    "NUM_CLASSES": 3,
    "CLASS_NAMES": ["angry", "happy", "sad"],
}

# Directories for training and validation datasets
train_directory = '/content/drive/MyDrive/dataset003 (1)/Emotions Dataset/Emotions Dataset/train'
val_directory = '/content/drive/MyDrive/dataset003 (1)/Emotions Dataset/Emotions Dataset/test'

"""**Loading datasets**"""

# Load training and validation datasets
train_dataset = tf.keras.utils.image_dataset_from_directory(
    train_directory,
    labels='inferred',
    label_mode='categorical',
    class_names=CONFIGURATION["CLASS_NAMES"],
    color_mode='rgb',
    batch_size=CONFIGURATION["BATCH_SIZE"],
    image_size=(CONFIGURATION["IM_SIZE"], CONFIGURATION["IM_SIZE"]),
    shuffle=True,
    seed=99,
)

val_dataset = tf.keras.utils.image_dataset_from_directory(
    val_directory,
    labels='inferred',
    label_mode='categorical',
    class_names=CONFIGURATION["CLASS_NAMES"],
    color_mode='rgb',
    batch_size=CONFIGURATION["BATCH_SIZE"],
    image_size=(CONFIGURATION["IM_SIZE"], CONFIGURATION["IM_SIZE"]),
    shuffle=True,
    seed=99,
)

"""**Building CNN model with regularization**"""

# Create the model with dropout regularization
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(CONFIGURATION["IM_SIZE"], CONFIGURATION["IM_SIZE"], 3)),
    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(CONFIGURATION["DROPOUT_RATE"]),
    tf.keras.layers.Dense(CONFIGURATION["NUM_CLASSES"], activation='softmax')
])

# Compile the model
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=CONFIGURATION["LEARNING_RATE"]),
    loss=tf.keras.losses.CategoricalCrossentropy(),
    metrics=[tf.keras.metrics.CategoricalAccuracy()]
)

"""**Training**"""

# Train the model
history = model.fit(train_dataset, epochs=CONFIGURATION["N_EPOCHS"], validation_data=val_dataset)

"""**Evaluation**"""

# Evaluate the model
val_loss, val_accuracy = model.evaluate(val_dataset)

print(f"Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}")

# Save the trained model with the native Keras format
model.save("emotion_model_updated.keras")

"""Prediction"""

# Provide the path to the image you want to predict
image_path_to_predict = "/content/pawankalyan.jpg"

# Define a function to preprocess an image for prediction
def preprocess_input_image_for_prediction(image_path):
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(CONFIGURATION["IM_SIZE"], CONFIGURATION["IM_SIZE"]))
    img = tf.keras.preprocessing.image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = img / 255.0  # Normalize the image
    return img

# Define a function to predict emotion from an image
def predict_emotion_from_image(image_path):
    input_img = preprocess_input_image_for_prediction(image_path)
    predictions = model.predict(input_img)
    class_names = CONFIGURATION["CLASS_NAMES"]
    predicted_emotion = class_names[np.argmax(predictions)]
    return predicted_emotion

# Make a prediction
predicted_emotion = predict_emotion_from_image(image_path_to_predict)

# Display the input image
from IPython.display import Image, display
display(Image(filename=image_path_to_predict))

# Display the predicted emotion
print("Predicted Emotion:", predicted_emotion)

"""**Visualization**"""

# Plot training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history["loss"], label="Training Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.legend()
plt.title("Loss vs. Epochs")

plt.subplot(1, 2, 2)
plt.plot(history.history["categorical_accuracy"], label="Training Accuracy")
plt.plot(history.history["val_categorical_accuracy"], label="Validation Accuracy")
plt.legend()
plt.title("Accuracy vs. Epochs")

plt.show()

